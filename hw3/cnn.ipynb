{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 3: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Sean Trinh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run my code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "4. Upload this .HTML file to your Github repo.\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/HM3/cnn.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    vect = []\n",
    "    for item in y:\n",
    "       x = [0]*item[0] + [1] + [0]*(num_class - 1 - item[0])\n",
    "       vect += [x]\n",
    "    return numpy.array(vect)\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 523,338\n",
      "Trainable params: 522,122\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 131s 3ms/step - loss: 1.2862 - acc: 0.5589 - val_loss: 1.0913 - val_acc: 0.6375\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 125s 3ms/step - loss: 0.9546 - acc: 0.6935 - val_loss: 1.2209 - val_acc: 0.6181\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 126s 3ms/step - loss: 0.8324 - acc: 0.7437 - val_loss: 0.8930 - val_acc: 0.7277\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 136s 3ms/step - loss: 0.7489 - acc: 0.7788 - val_loss: 0.9212 - val_acc: 0.7256\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 140s 3ms/step - loss: 0.6834 - acc: 0.8060 - val_loss: 1.1622 - val_acc: 0.6790\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 138s 3ms/step - loss: 0.6421 - acc: 0.8254 - val_loss: 0.8598 - val_acc: 0.7696\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 143s 4ms/step - loss: 0.5981 - acc: 0.8462 - val_loss: 0.8462 - val_acc: 0.7715\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 135s 3ms/step - loss: 0.5699 - acc: 0.8600 - val_loss: 1.2160 - val_acc: 0.7070\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 138s 3ms/step - loss: 0.5384 - acc: 0.8749 - val_loss: 1.0221 - val_acc: 0.7343\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 132s 3ms/step - loss: 0.5169 - acc: 0.8861 - val_loss: 1.2091 - val_acc: 0.7123\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=90, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "datagen.fit(x_train)\n",
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=learning_rate), metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 0.6277 - acc: 0.8594\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.5808 - acc: 0.8741\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 0.5492 - acc: 0.8862\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 168s 3ms/step - loss: 0.5398 - acc: 0.8919\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 0.5286 - acc: 0.9008\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 0.5217 - acc: 0.9060\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 0.5155 - acc: 0.9088\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 168s 3ms/step - loss: 0.5121 - acc: 0.9116\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 0.5075 - acc: 0.9148\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 0.5061 - acc: 0.9181\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train_vec, batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 642us/step\n",
      "loss = 1.5123439922332764\n",
      "accuracy = 0.7188\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
